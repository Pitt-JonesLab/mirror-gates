{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# make a graph that shows convergence as a function of layout trials and swap trials\n",
        "\n",
        "# very important point to not forget\n",
        "# NOTE, these layout trials are after multiple SWAP trials and through forward-backwards pass\n",
        "# this means it has already gone through 2 stages of optimization and we still have large variance\n",
        "\n",
        "# ultimate question is how much time do we need to spend on swap restarts, forward-backward passes, and layout restarts\n",
        "# maybe we work from bottom up, collect data to get a fair estimate of how much time we need to spend on each?\n",
        "\n",
        "from qiskit.transpiler import CouplingMap\n",
        "from mirror_gates.pass_managers import SabreMS, QiskitLevel3\n",
        "from transpile_benchy.metrics.abc_metrics import MetricInterface\n",
        "from transpile_benchy.metrics.gate_counts import DepthMetric\n",
        "from mirror_gates.utilities import DoNothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LayoutTrialsStdMetric(MetricInterface):\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the metric.\"\"\"\n",
        "        super().__init__(\n",
        "            name=\"layout_trials_std\", pretty_name=\"Layout Trial Standard Deviation\"\n",
        "        )\n",
        "\n",
        "    def _construct_pass(self):\n",
        "        \"\"\"Return the pass associated with this metric.\"\"\"\n",
        "        return DoNothing()\n",
        "\n",
        "\n",
        "class LayoutTrialsMetric(MetricInterface):\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the metric.\"\"\"\n",
        "        super().__init__(name=\"layout_trials\", pretty_name=\"Layout Trial Costs\")\n",
        "\n",
        "    def _construct_pass(self):\n",
        "        \"\"\"Return the pass associated with this metric.\"\"\"\n",
        "        return DoNothing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transpile_benchy.library import CircuitLibrary\n",
        "\n",
        "# library = CircuitLibrary.from_txt(\"../medium_circuits.txt\")\n",
        "# library = CircuitLibrary.from_txt(\"iterations.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "coupling_map = CouplingMap.from_heavy_hex(5)\n",
        "transpilers = [\n",
        "    # QiskitLevel3(coupling_map),\n",
        "    SabreMS(coupling_map, name=\"SABREMS\", layout_trials=20)\n",
        "]\n",
        "\n",
        "metrics = [LayoutTrialsMetric(), DepthMetric(consolidate=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "coupling_map = CouplingMap.from_heavy_hex(5)\n",
        "transpilers = [\n",
        "    # QiskitLevel3(coupling_map),\n",
        "    SabreMS(coupling_map, name=\"SABREMS\", anneal_routing=False),\n",
        "    SabreMS(coupling_map, name=\"SABREMS-Anneal\", anneal_routing=True),\n",
        "]\n",
        "\n",
        "metrics = [LayoutTrialsMetric(), DepthMetric(consolidate=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "coupling_map = CouplingMap.from_heavy_hex(5)\n",
        "transpilers = [\n",
        "    # QiskitLevel3(coupling_map),\n",
        "    SabreMS(coupling_map, name=\"SABREMS-MinSwaps\", cost_function=\"basic\"),\n",
        "    SabreMS(coupling_map, name=\"SABREMS-MinDepth\"),\n",
        "]\n",
        "\n",
        "metrics = [DepthMetric(consolidate=False)]  # , TotalMetric(consolidate=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Circuits from library:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading qft_n8 from MQTBench\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Circuits from library:  25%|\u2588\u2588\u258c       | 1/4 [01:21<04:03, 81.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading qft_n16 from MQTBench\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Circuits from library:  50%|\u2588\u2588\u2588\u2588\u2588     | 2/4 [04:09<04:25, 132.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading qft_n32 from MQTBench\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Circuits from library: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [13:55<00:00, 208.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading qft_n64 from MQTBench\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from transpile_benchy.benchmark import Benchmark\n",
        "\n",
        "# only interested in TimeMetric, is there by default\n",
        "benchmark = Benchmark(\n",
        "    transpilers=transpilers,\n",
        "    circuit_library=library,\n",
        "    metrics=metrics,\n",
        "    num_runs=10,\n",
        ")\n",
        "benchmark.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Transpiler: SABREMS-MinDepth-$\\sqrt{\\texttt{iSWAP}}$\n",
            "\n",
            "  Metric: monodromy_depth\n",
            "  Circuit: qft_n16                                  Mean result: 63.543                         Trials: [70.5, 96.0, 73.0, 66.0, 42.5, 45.5, 71.0, 60.0, 42.5, 94.0]\n",
            "  Circuit: qft_n32                                  Mean result: 188.362                        Trials: [171.5, 207.5, 187.5, 240.5, 127.0, 171.0, 182.5, 254.5, 235.5, 147.5]\n",
            "  Circuit: qft_n8                                   Mean result: 21.089                         Trials: [20.5, 18.5, 22.5, 20.5, 18.5, 28.0, 18.5, 20.5, 22.5, 22.5]\n",
            "\n",
            "  Metric: total_runtime\n",
            "  Circuit: qft_n16                                  Mean result: 8.576                          Trials: [8.211485147476196, 8.583486318588257, 8.431179285049438, 8.396565675735474, 8.492676973342896, 8.351712226867676, 9.047089338302612, 8.211954832077026, 8.91487455368042, 9.121588945388794]\n",
            "  Circuit: qft_n32                                  Mean result: 29.116                         Trials: [28.565086603164673, 28.843127489089966, 29.265960216522217, 29.373541831970215, 28.48138165473938, 29.11115837097168, 29.540480375289917, 29.325552225112915, 28.9910671710968, 29.661743879318237]\n",
            "  Circuit: qft_n8                                   Mean result: 3.987                          Trials: [3.8348841667175293, 3.8752429485321045, 3.806095600128174, 4.341133117675781, 4.233761548995972, 4.081031560897827, 3.995513439178467, 4.023674011230469, 3.922907829284668, 3.7538039684295654]\n",
            "\n",
            "Transpiler: SABREMS-MinSwaps-$\\sqrt{\\texttt{iSWAP}}$\n",
            "\n",
            "  Metric: monodromy_depth\n",
            "  Circuit: qft_n16                                  Mean result: 68.920                         Trials: [60.0, 101.0, 52.0, 95.0, 42.5, 45.5, 115.0, 64.5, 42.5, 132.5]\n",
            "  Circuit: qft_n32                                  Mean result: 210.798                        Trials: [116.5, 236.5, 250.0, 257.5, 125.0, 184.5, 323.0, 330.5, 150.0, 264.5]\n",
            "  Circuit: qft_n8                                   Mean result: 21.169                         Trials: [20.5, 18.5, 22.5, 22.5, 18.5, 22.5, 18.5, 20.5, 26.5, 22.5]\n",
            "\n",
            "  Metric: total_runtime\n",
            "  Circuit: qft_n16                                  Mean result: 8.290                          Trials: [7.915899038314819, 8.32769250869751, 8.299270629882812, 8.543641567230225, 8.055408000946045, 8.167233943939209, 8.399335861206055, 8.513734817504883, 8.10731053352356, 8.569547176361084]\n",
            "  Circuit: qft_n32                                  Mean result: 29.463                         Trials: [30.029062509536743, 28.635237455368042, 31.52879810333252, 29.745732307434082, 28.38453459739685, 29.10513162612915, 27.89491295814514, 29.32042121887207, 29.348707914352417, 30.641703128814697]\n",
            "  Circuit: qft_n8                                   Mean result: 4.117                          Trials: [4.08127236366272, 3.6855435371398926, 4.260279893875122, 3.945819139480591, 4.567833662033081, 3.9113845825195312, 4.7406229972839355, 4.145765542984009, 4.038717985153198, 3.797661066055298]\n"
          ]
        }
      ],
      "source": [
        "print(benchmark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'SABREMS-MinSwaps-$\\\\sqrt{\\\\texttt{iSWAP}}$': {'qft_n8': Result(monodromy_depth, 21.168977697667533),\n",
              "  'qft_n16': Result(monodromy_depth, 68.92015195537596),\n",
              "  'qft_n32': Result(monodromy_depth, 210.79832796050073)},\n",
              " 'SABREMS-MinDepth-$\\\\sqrt{\\\\texttt{iSWAP}}$': {'qft_n8': Result(monodromy_depth, 21.08862360097365),\n",
              "  'qft_n16': Result(monodromy_depth, 63.542659175402655),\n",
              "  'qft_n32': Result(monodromy_depth, 188.361959494601)}}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "benchmark.metrics[0].saved_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SABREMS-MinSwaps-$\\sqrt{\\texttt{iSWAP}}$\n"
          ]
        },
        {
          "ename": "AxisError",
          "evalue": "axis 1 is out of bounds for array of dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(k)\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m circuit, result \u001b[39min\u001b[39;00m v\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      9\u001b[0m     \u001b[39m# print(circuit)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39m# print(result.data)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m     \u001b[39m# find cumulative min trial-wise\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     min_trials \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mminimum\u001b[39m.\u001b[39;49maccumulate(result\u001b[39m.\u001b[39;49mdata, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(min_trials\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     15\u001b[0m     \u001b[39m# print(min_trials)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m     \u001b[39m# average element-wise across all trials\u001b[39;00m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming benchmark.metrics[0].saved_results.items() is a dictionary\n",
        "# where keys are circuit names and values are lists of costs for each trial\n",
        "for k, v in benchmark.metrics[0].saved_results.items():\n",
        "    print(k)\n",
        "    for circuit, result in v.items():\n",
        "        # print(circuit)\n",
        "        # print(result.data)\n",
        "\n",
        "        # find cumulative min trial-wise\n",
        "        min_trials = np.minimum.accumulate(result.data, axis=1)\n",
        "        print(min_trials.shape)\n",
        "        # print(min_trials)\n",
        "\n",
        "        # average element-wise across all trials\n",
        "        avg = np.mean(min_trials, axis=0)\n",
        "        # print(avg)\n",
        "\n",
        "        # plot cumulative min vs trial\n",
        "        # also plot average cumulative min vs trial\n",
        "        # at each trial we also want to scatter plot each individual trial,\n",
        "\n",
        "        # plot with latex\n",
        "        with plt.style.context([\"ipynb\", \"colorsblind10\"]):\n",
        "            plt.rcParams[\"text.usetex\"] = True\n",
        "            for j, trials in enumerate(min_trials):\n",
        "                plt.plot(\n",
        "                    trials,\n",
        "                    color=\"blue\",\n",
        "                    alpha=0.1,\n",
        "                    label=\"Individual Trials\" if j == 0 else None,\n",
        "                )\n",
        "            plt.plot(avg, color=\"red\", label=\"Average\")\n",
        "            plt.xlabel(\"Layout Trials\")\n",
        "            plt.ylabel(\"Cumulative Min Cost\")\n",
        "            plt.title(f\"{k} {circuit}\")\n",
        "            plt.ticklabel_format(style=\"plain\")  # Turn off scientific notation\n",
        "            plt.legend()\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # explictly print results\n",
        "# for k, v in benchmark.metrics[0].saved_results.items():\n",
        "#     for circuit, result in v.items():\n",
        "#         print(result.data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
